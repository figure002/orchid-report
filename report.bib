@article{Agarwal2006,
author = {Agarwal, Gaurav and Belhumeur, Peter and Feiner, Steven},
file = {:home/serrano/Documents/eBooks/Mendeley/Taxon/Agarwal, Belhumeur, Feiner/Agarwal, Belhumeur, Feiner - 2006 - First steps toward an electronic field guide for plants.pdf:pdf},
journal = {Taxon},
keywords = {augmented reality,computer vision,content-based image retrieval,distance,electronic field guide,inner-,mobile computing,recognition,shape matching,species identification,type specimens,wearable},
number = {August},
pages = {597--610},
title = {{First steps toward an electronic field guide for plants}},
url = {http://www.ingentaconnect.com/content/iapt/tax/2006/00000055/00000003/art00008},
volume = {55},
year = {2006}
}
@article{Arefi2011,
author = {Arefi, Arman and Motlagh, Asad Modarres and Khoshroo, Alireza},
file = {:home/serrano/Documents/eBooks/Mendeley/Food, Agriculture and Environment (JFAE)/Arefi, Motlagh, Khoshroo/Arefi, Motlagh, Khoshroo - 2011 - Recognition of weed seed species by image processing.pdf:pdf},
journal = {Food, Agriculture and Environment (JFAE)},
keywords = {image processing,machine vision,variety identification,weed seed},
pages = {379--383},
title = {{Recognition of weed seed species by image processing}},
year = {2011}
}
@article{Arinkin2014,
abstract = {BACKGROUND: True date palms (Phoenix dactylifera L.) are impressive trees and have served as an indispensable source of food for mankind in tropical and subtropical countries for centuries. The aim of this study is to differentiate date palm tree varieties by analysing leaflet cross sections with technical/optical methods and artificial neural networks (ANN). RESULTS: Fluorescence microscopy images of leaflet cross sections have been taken from a set of five date palm tree cultivars (Hewlat al Jouf, Khlas, Nabot Soltan, Shishi, Um Raheem). After features extraction from images, the obtained data have been fed in a multilayer perceptron ANN with backpropagation learning algorithm. CONCLUSIONS: Overall, an accurate result in prediction and differentiation of date palm tree cultivars was achieved with average prediction in tenfold cross-validation is 89.1\% and reached 100\% in one of the best ANN.},
author = {Arinkin, Vladimir and Digel, Ilya and Porst, Dariusz and Artmann, Ayseg\"{u}l Temiz and Artmann, Gerhard M},
doi = {10.1186/1471-2105-15-55},
file = {:home/serrano/Documents/eBooks/Mendeley/BMC bioinformatics/Arinkin et al/Arinkin et al. - 2014 - Phenotyping date palm varieties via leaflet cross-sectional imaging and artificial neural network application.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Arecaceae,Arecaceae: classification,Arecaceae: ultrastructure,Computer-Assisted,Computer-Assisted: methods,Fluorescence,Image Processing,Microscopy,Neural Networks (Computer),Phenotype,Plant Leaves,Plant Leaves: ultrastructure},
month = jan,
number = {55},
pages = {55},
pmid = {24564551},
title = {{Phenotyping date palm varieties via leaflet cross-sectional imaging and artificial neural network application.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3941935\&tool=pmcentrez\&rendertype=abstract},
volume = {15},
year = {2014}
}
@article{Boddy1994,
abstract = {Flow cytometry data (time of flight, horizontal and vertical forward light scatter, 90 degrees light scatter, and "red" and "orange" integral fluorescence) were collected for laboratory cultures of 40 species of marine phytoplankton, from the following taxonomic classes, the Dinophyceae, Bacillariophyceae, Prymnesiophyceae, Cryptophyceae, and other flagellates. Single-hidden-layer "back-propagation" neural networks were trained to discriminate between species by recognising patterns in their flow cytometric signatures, and network performance was assessed using an independent test data set. Two approaches were adopted employing: (1) a hierarchy of small networks, the first identifying to which major taxonomic group a cell belonged, and then a network for that taxonomic group identified to species, and (2) a single large network. Discriminating some of the major taxonomic groups was successful but others less so. With networks for specific groups, cryptophyte species were all identified reliably (probability of correct classification always being > 0.75); in the other groups half of the species were identified reliably. With the large network, dinoflagellates, cryptomonads, and flagellates were identified almost as well as by networks specific for these groups. The application of neural computing techniques to identification of such a large number of species represents a significant advance from earlier studies, although further development is required.},
author = {Boddy, L and Morris, C W and Wilkins, M F and Tarran, G a and Burkill, P H},
doi = {10.1002/cyto.990150403},
file = {:home/serrano/Documents/eBooks/Mendeley/Cytometry/Boddy et al/Boddy et al. - 1994 - Neural network analysis of flow cytometric data for 40 marine phytoplankton species.pdf:pdf},
issn = {0196-4763},
journal = {Cytometry},
keywords = {Flow Cytometry,Marine Biology,Marine Biology: methods,Neural Networks (Computer),North Sea,Phytoplankton,Phytoplankton: classification,Species Specificity},
month = apr,
number = {4},
pages = {283--93},
pmid = {8026219},
title = {{Neural network analysis of flow cytometric data for 40 marine phytoplankton species.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8026219},
volume = {15},
year = {1994}
}
@article{Chochai2012,
abstract = {Phylogenetic relationships in the genus Paphiopedilum were studied using nuclear ribosomal internal transcribed spacer (ITS) and plastid sequence data. The results conﬁrm that the genus Paphiopedilum is monophyletic, and the division of the genus into three subgenera Parvisepalum, Brachypetalum and Paphiopedilum is well supported. Four sections of subgenus Paphiopedilum (Pardalopetalum, Cochlopetalum, Paphiopedilum and Barbata) are recovered as in a recent infrageneric treatment, with strong support. Section Coryopedilum is also recovered, with low bootstrap but high posterior probability values for support of monophyly. Relationships in section Barbata remain unresolved, and short branch lengths and the narrow geographical distribution of many species in the section suggest that it possibly underwent rapid radiation. Mapping chromosome and genome size data (including some new genome size measurements) onto the phylogenetic framework shows that there is no clear trend in increase in chromosome number in the genus. However, the diploid chromosome number of 2n = 26 in subgenera Parvisepalum and Brachypetalum suggests that this is the ancestral condition, and higher chromosome numbers in sections Cochlopetalum and Barbata suggest that centric ﬁssion has possibly occurred in parallel in these sections. The trend for genome size evolution is also unclear, although species in section Barbata have larger genome sizes than those in other sections.},
author = {Chochai, Araya and Leitch, Ilia J and Ingrouille, Martin J and Fay, Michael F.},
doi = {10.1111/j.1095-8339.2012.01293.x},
file = {:home/serrano/Documents/eBooks/Mendeley/Botanical Journal of the Linnean Society/Chochai et al/Chochai et al. - 2012 - Molecular phylogenetics of Paphiopedilum (Cypripedioideae Orchidaceae) based on nuclear ribosomal ITS and plasti.pdf:pdf},
issn = {00244074},
journal = {Botanical Journal of the Linnean Society},
month = oct,
number = {2},
pages = {176--196},
title = {{Molecular phylogenetics of Paphiopedilum (Cypripedioideae; Orchidaceae) based on nuclear ribosomal ITS and plastid sequences}},
url = {http://doi.wiley.com/10.1111/j.1095-8339.2012.01293.x},
volume = {170},
year = {2012}
}
@book{Cribb1998,
address = {Kota Kinabalu},
author = {Cribb, Phillip J.},
edition = {Second},
isbn = {9838120235},
pages = {427},
publisher = {Natural History Publications (Borneo) Sdn. Bhd.},
title = {{The Genus Paphiopedilum}},
year = {1998}
}
@article{Dietterich1995,
author = {Dietterich, Thomas G and Bakiri, G},
doi = {10.1613/jair.105},
file = {:home/serrano/Documents/eBooks/Mendeley/Journal of Artifcial Intelligence Research/Dietterich, Bakiri/Dietterich, Bakiri - 1995 - Solving Multiclass Learning Problems via Error-Correcting Output Codes.pdf:pdf},
journal = {Journal of Artifcial Intelligence Research},
title = {{Solving Multiclass Learning Problems via Error-Correcting Output Codes}},
volume = {2},
year = {1995}
}
@article{Domingos2012,
author = {Domingos, Pedro},
file = {:home/serrano/Documents/eBooks/Mendeley/Communications of the ACM/Domingos/Domingos - 2012 - A few useful things to know about machine learning.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = oct,
number = {10},
pages = {78},
publisher = {ACM},
title = {{A few useful things to know about machine learning}},
url = {http://dl.acm.org/ft\_gateway.cfm?id=2347755\&type=html},
volume = {55},
year = {2012}
}
@article{Egmont-Petersen2002,
author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H},
doi = {10.1016/S0031-3203(01)00178-9},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition/Egmont-petersen, Ridder, Handels/Egmont-petersen, Ridder, Handels - 2002 - Image processing with neural networks — a review.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {compression,digital image processing,feature extraction,image,image understanding,invariant pattern recognition,neural networks,object recognition,optimization,preprocessing,segmentation},
month = oct,
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks—a review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001789},
volume = {35},
year = {2002}
}
@article{Flusser2006,
author = {Flusser, Jan},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Flusser/Flusser - 2006 - Moment Invariants in Image Analysis.pdf:pdf},
keywords = {degraded images,geometric invariants,invariants to convolu-,moment computation,moment invariants,moments,object recognition,tion},
number = {102},
title = {{Moment Invariants in Image Analysis}},
volume = {11},
year = {2006}
}
@book{Frosch2012,
address = {Richmond},
author = {Frosch, Werner and Cribb, Phillip},
isbn = {978-1842464649},
pages = {156},
publisher = {Royal Botanic Gardens, Kew},
title = {{Hardy Cypripedium: Species, Hybrids and Cultivation}},
year = {2012}
}
@article{Han2012,
abstract = {This paper presents a feasibility study on a real-time in field pest classification system design based on Blackfin DSP and 3G wireless communication technology. This prototype system is composed of remote on-line classification platform (ROCP), which uses a digital signal processor (DSP) as a core CPU, and a host control platform (HCP). The ROCP is in charge of acquiring the pest image, extracting image features and detecting the class of pest using an Artificial Neural Network (ANN) classifier. It sends the image data, which is encoded using JPEG 2000 in DSP, to the HCP through the 3G network at the same time for further identification. The image transmission and communication are accomplished using 3G technology. Our system transmits the data via a commercial base station. The system can work properly based on the effective coverage of base stations, no matter the distance from the ROCP to the HCP. In the HCP, the image data is decoded and the pest image displayed in real-time for further identification. Authentication and performance tests of the prototype system were conducted. The authentication test showed that the image data were transmitted correctly. Based on the performance test results on six classes of pests, the average accuracy is 82\%. Considering the different live pests' pose and different field lighting conditions, the result is satisfactory. The proposed technique is well suited for implementation in field pest classification on-line for precision agriculture.},
author = {Han, Ruizhen and He, Yong and Liu, Fei},
doi = {10.3390/s120303118},
file = {:home/serrano/Documents/eBooks/Mendeley/Sensors (Basel, Switzerland)/Han, He, Liu/Han, He, Liu - 2012 - Feasibility study on a portable field pest classification system design based on DSP and 3G wireless communication.pdf:pdf},
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
month = jan,
number = {3},
pages = {3118--30},
pmid = {22736996},
title = {{Feasibility study on a portable field pest classification system design based on DSP and 3G wireless communication technology.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3376617\&tool=pmcentrez\&rendertype=abstract},
volume = {12},
year = {2012}
}
@article{Hansen1990,
author = {Hansen, L.K. and Salamon, P.},
doi = {10.1109/34.58871},
file = {:home/serrano/Documents/eBooks/Mendeley/IEEE Transactions on Pattern Analysis and Machine Intelligence/Hansen, Salamon/Hansen, Salamon - 1990 - Neural network ensembles.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {993--1001},
title = {{Neural network ensembles}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=58871},
volume = {12},
year = {1990}
}
@article{Houle2003,
abstract = {BACKGROUND: Many studies in evolutionary biology and genetics are limited by the rate at which phenotypic information can be acquired. The wings of Drosophila species are a favorable target for automated analysis because of the many interesting questions in evolution and development that can be addressed with them, and because of their simple structure. RESULTS: We have developed an automated image analysis system (WINGMACHINE) that measures the positions of all the veins and the edges of the wing blade of Drosophilid flies. A video image is obtained with the aid of a simple suction device that immobilizes the wing of a live fly. Low-level processing is used to find the major intersections of the veins. High-level processing then optimizes the fit of an a priori B-spline model of wing shape. WINGMACHINE allows the measurement of 1 wing per minute, including handling, imaging, analysis, and data editing. The repeatabilities of 12 vein intersections averaged 86\% in a sample of flies of the same species and sex. Comparison of 2400 wings of 25 Drosophilid species shows that wing shape is quite conservative within the group, but that almost all taxa are diagnosably different from one another. Wing shape retains some phylogenetic structure, although some species have shapes very different from closely related species. The WINGMACHINE system facilitates artificial selection experiments on complex aspects of wing shape. We selected on an index which is a function of 14 separate measurements of each wing. After 14 generations, we achieved a 15 S.D. difference between up and down-selected treatments. CONCLUSION: WINGMACHINE enables rapid, highly repeatable measurements of wings in the family Drosophilidae. Our approach to image analysis may be applicable to a variety of biological objects that can be represented as a framework of connected lines.},
author = {Houle, David and Mezey, Jason and Galpern, Paul and Carter, Ashley},
doi = {10.1186/1471-2148-3-25},
file = {:home/serrano/Documents/eBooks/Mendeley/BMC evolutionary biology/Houle et al/Houle et al. - 2003 - Automated measurement of Drosophila wings.pdf:pdf},
issn = {1471-2148},
journal = {BMC evolutionary biology},
keywords = {Animals,Computer-Assisted,Computer-Assisted: instrumentati,Computer-Assisted: methods,Drosophila,Drosophila: anatomy \& histology,Image Processing,Microscopy,Phenotype,Reproducibility of Results,Software,Video,Video: instrumentation,Video: methods,Wing,Wing: anatomy \& histology},
month = dec,
pages = {25},
pmid = {14670094},
title = {{Automated measurement of Drosophila wings}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=317280\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2003}
}
@article{Hse2004,
author = {Hse, H. and a.R. Newton},
doi = {10.1109/ICPR.2004.1334128},
file = {:home/serrano/Documents/eBooks/Mendeley/Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004/Hse, Newton/Hse, Newton - 2004 - Sketched symbol recognition using Zernike moments.pdf:pdf},
isbn = {0-7695-2128-2},
journal = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
pages = {367--370 Vol.1},
publisher = {Ieee},
title = {{Sketched symbol recognition using Zernike moments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334128},
year = {2004}
}
@article{Hu1962,
author = {Hu, Ming-Kuei},
doi = {10.1109/TIT.1962.1057692},
file = {:home/serrano/Documents/eBooks/Mendeley/IEEE Transactions on Information Theory/Hu/Hu - 1962 - Visual pattern recognition by moment invariants.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = feb,
number = {2},
pages = {179--187},
title = {{Visual pattern recognition by moment invariants}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1057692},
volume = {8},
year = {1962}
}
@article{Hwang2006,
author = {Hwang, Sun-Kyoo and Kim, Whoi-Yul},
doi = {10.1016/j.patcog.2006.03.004},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition/Hwang, Kim/Hwang, Kim - 2006 - A novel approach to the fast computation of Zernike moments.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {anti-symmetry,discrete zernike moments,fast method,symmetry,zernike moments},
month = nov,
number = {11},
pages = {2065--2076},
title = {{A novel approach to the fast computation of Zernike moments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320306001166},
volume = {39},
year = {2006}
}
@article{Kang2012,
author = {Kang, Seung-Ho and Song, Su-Hee and Lee, Sang-Hee},
doi = {10.1016/j.aspen.2012.03.006},
file = {:home/serrano/Documents/eBooks/Mendeley/Journal of Asia-Pacific Entomology/Kang, Song, Lee/Kang, Song, Lee - 2012 - Identification of butterfly species with a single neural network system.pdf:pdf},
issn = {12268615},
journal = {Journal of Asia-Pacific Entomology},
keywords = {automatic species identification},
month = sep,
number = {3},
pages = {431--435},
title = {{Identification of butterfly species with a single neural network system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1226861512000374},
volume = {15},
year = {2012}
}
@article{Kasparek1999,
author = {Kasparek, Max and Grimm, Ute},
doi = {10.1007/BF02866718},
file = {::},
issn = {0013-0001},
journal = {Economic Botany},
keywords = {at the beginning of,become,increasingly clear that germany,international trade,is one of the,nature con-,non-wood forest products,orchids,servation,species protection,sustainability,the 1990s it has},
month = oct,
number = {4},
pages = {396--406},
title = {{European trade in Turkish Salep with special reference to Germany}},
url = {http://link.springer.com/10.1007/BF02866718},
volume = {53},
year = {1999}
}
@article{Kloster2014,
abstract = {BACKGROUND: Light microscopic analysis of diatom frustules is widely used both in basic and applied research, notably taxonomy, morphometrics, water quality monitoring and paleo-environmental studies. In these applications, usually large numbers of frustules need to be identified and / or measured. Although there is a need for automation in these applications, and image processing and analysis methods supporting these tasks have previously been developed, they did not become widespread in diatom analysis. While methodological reports for a wide variety of methods for image segmentation, diatom identification and feature extraction are available, no single implementation combining a subset of these into a readily applicable workflow accessible to diatomists exists.

RESULTS: The newly developed tool SHERPA offers a versatile image processing workflow focused on the identification and measurement of object outlines, handling all steps from image segmentation over object identification to feature extraction, and providing interactive functions for reviewing and revising results. Special attention was given to ease of use, applicability to a broad range of data and problems, and supporting high throughput analyses with minimal manual intervention.

CONCLUSIONS: Tested with several diatom datasets from different sources and of various compositions, SHERPA proved its ability to successfully analyze large amounts of diatom micrographs depicting a broad range of species. SHERPA is unique in combining the following features: application of multiple segmentation methods and selection of the one giving the best result for each individual object; identification of shapes of interest based on outline matching against a template library; quality scoring and ranking of resulting outlines supporting quick quality checking; extraction of a wide range of outline shape descriptors widely used in diatom studies and elsewhere; minimizing the need for, but enabling manual quality control and corrections. Although primarily developed for analyzing images of diatom valves originating from automated microscopy, SHERPA can also be useful for other object detection, segmentation and outline-based identification problems.},
author = {Kloster, Michael and Kauer, Gerhard and Beszteri, B\'{a}nk},
doi = {10.1186/1471-2105-15-218},
file = {:home/serrano/Documents/eBooks/Mendeley/BMC bioinformatics/Kloster, Kauer, Beszteri/Kloster, Kauer, Beszteri - 2014 - SHERPA an image segmentation and outline feature extraction tool for diatoms and other objects.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
month = jun,
number = {1},
pages = {218},
pmid = {24964954},
title = {{SHERPA: an image segmentation and outline feature extraction tool for diatoms and other objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24964954},
volume = {15},
year = {2014}
}
@incollection{Kumar2012,
abstract = {We describe the first mobile app for identifying plant species using automatic visual recognition. The system – called Leafsnap – identifies tree species from photographs of their leaves. Key to this system are computer vision components for discarding non-leaf images, segmenting the leaf from an untextured background, extracting features representing the curvature of the leaf’s contour over multiple scales, and identifying the species from a dataset of the 184 trees in the Northeastern United States. Our system obtains state-of-the-art performance on the real-world images from the new Leafsnap Dataset – the largest of its kind. Throughout the paper, we document many of the practical steps needed to produce a computer vision system such as ours, which currently has nearly a million users.},
author = {Kumar, Neeraj and Belhumeur, Peter N and Biswas, Arijit and Jacobs, David W},
booktitle = {Computer Vision – ECCV 2012},
doi = {10.1007/978-3-642-33709-3\_36},
file = {:home/serrano/Documents/eBooks/Mendeley/Computer Vision – ECCV 2012/Kumar et al/Kumar et al. - 2012 - Leafsnap A Computer Vision System for Automatic Plant Species Identification.pdf:pdf},
isbn = {978-3-642-33709-3},
pages = {502--516},
title = {{Leafsnap: A Computer Vision System for Automatic Plant Species Identification}},
url = {http://dx.doi.org/10.1007/978-3-642-33709-3\_36},
year = {2012}
}
@inproceedings{Kumar,
author = {Kumar, S.R. and Mitra, Mandar and Zabih, Ramin},
booktitle = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.1997.609412},
file = {:home/serrano/Documents/eBooks/Mendeley/Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition/Kumar, Mitra, Zabih/Kumar, Mitra, Zabih - Unknown - Image indexing using color correlograms.pdf:pdf},
isbn = {0-8186-7822-4},
pages = {762--768},
publisher = {IEEE Comput. Soc},
title = {{Image indexing using color correlograms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=609412}
}
@article{Lempitsky2011,
author = {Lempitsky, Victor and Zisserman, Andrew},
doi = {10.1109/ICCV.2011.6126546},
file = {:home/serrano/Documents/eBooks/Mendeley/2011 International Conference on Computer Vision/Lempitsky, Zisserman/Lempitsky, Zisserman - 2011 - BiCoS A Bi-level co-segmentation method for image classification.pdf:pdf},
isbn = {978-1-4577-1102-2},
journal = {2011 International Conference on Computer Vision},
month = nov,
pages = {2579--2586},
publisher = {Ieee},
title = {{BiCoS: A Bi-level co-segmentation method for image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126546},
year = {2011}
}
@article{Li2011,
abstract = {A molecular analysis was performed on 56 taxa in the orchid genus Cypripedium using nrDNA ITS and five chloroplast regions (trnH-psbA, atpI-atpH, trnS-trnfM, trnL-F spacer, and the trnL intron). The genus Cypripedium was confirmed as monophyletic. Our data provided strong support for monophyletic grouping of eight infrageneric sections (Subtropica, Obtusipetala, Trigonopedia, Sinopedilum, Bifolia, Flabelinervia, Arietinum, and Cypripedium) defined in earlier taxonomic treatments, and paraphyletic grouping of two sections (Irapeana and Retinervi). Within the genus Cypripedium, the first divergent lineage consisted of two Mesomaerican species, and subsequently the Cypripedium debile lineage from eastern Asia was split. Our study did not support the notion that two Asian species (Cypripedium subtropicum and Cypripedium singchii) were closely related to either Mesoamerican Cypripedium irapeanum or North American Cypripedium californicum, as indicated by previous interpretations based on morphological evidences. In addition, one pair of vicariant species, Cypripedium plectrochilum (eastern Asia) and Cypripedium arietinum (North America), unique to section Arietinum, was confirmed. Furthermore, within the monophyletic section Cypripedium two previously recognized subsections, Cypripedium and Macrantha, were shown to be paraphyletic. Our results suggested that this section split into two groups based on distribution (North America vs. Eurasia) instead of such previously used, morphological traits as flower color, and the shape of the lips (labellum) and lateral petals.},
author = {Li, Ji-hong and Liu, Zhong-jian and Salazar, Gerardo a and Bernhardt, Peter and Perner, Holger and Tomohisa, Yukawa and Jin, Xiao-hua and Chung, Shih-wen and Luo, Yi-bo},
doi = {10.1016/j.ympev.2011.06.006},
file = {:home/serrano/Documents/eBooks/Mendeley/Molecular phylogenetics and evolution/Li et al/Li et al. - 2011 - Molecular phylogeny of Cypripedium (Orchidaceae Cypripedioideae) inferred from multiple nuclear and chloroplast regio.pdf:pdf},
issn = {1095-9513},
journal = {Molecular phylogenetics and evolution},
keywords = {Cell Nucleus,Cell Nucleus: genetics,Chloroplast,Chloroplast: genetics,DNA,Evolution,Flowers,Flowers: genetics,Molecular,Orchidaceae,Orchidaceae: classification,Orchidaceae: genetics,Phylogeny,Plant,Plant: genetics,Ribosomal Spacer,Ribosomal Spacer: genetics,Sequence Analysis},
month = nov,
number = {2},
pages = {308--20},
pmid = {21718793},
publisher = {Elsevier Inc.},
title = {{Molecular phylogeny of Cypripedium (Orchidaceae: Cypripedioideae) inferred from multiple nuclear and chloroplast regions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21718793},
volume = {61},
year = {2011}
}
@article{Liao1996,
author = {Liao, S.X. and Pawlak, M.},
doi = {10.1109/34.485554},
file = {:home/serrano/Documents/eBooks/Mendeley/IEEE Transactions on Pattern Analysis and Machine Intelligence/Liao, Pawlak/Liao, Pawlak - 1996 - On image analysis by moments.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = mar,
number = {3},
pages = {254--266},
title = {{On image analysis by moments}},
url = {http://dx.doi.org/10.1109/34.485554 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=485554},
volume = {18},
year = {1996}
}
@article{MacLeod2010,
author = {MacLeod, Norman and Benfield, Mark and Culverhouse, Phil},
doi = {10.1038/467154a},
file = {:home/serrano/Documents/eBooks/Mendeley/Nature/MacLeod, Benfield, Culverhouse/MacLeod, Benfield, Culverhouse - 2010 - Time to automate identification.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Automation,Classification,Classification: methods,Marine Biology,Marine Biology: methods,Zooplankton,Zooplankton: classification},
month = sep,
number = {7312},
pages = {154--5},
pmid = {20829777},
title = {{Time to automate identification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20829777},
volume = {467},
year = {2010}
}
@article{Murphey2004,
author = {Murphey, Yi L. and Guo, Hong and Feldkamp, Lee A.},
doi = {10.1023/B:APIN.0000033632.42843.17},
file = {:home/serrano/Documents/eBooks/Mendeley/Applied Intelligence/Murphey, Guo, Feldkamp/Murphey, Guo, Feldkamp - 2004 - Neural Learning from Unbalanced Data.pdf:pdf},
issn = {0924-669X},
journal = {Applied Intelligence},
keywords = {data noise,machine learning,neural networks,unbalanced data},
month = sep,
number = {2},
pages = {117--128},
title = {{Neural Learning from Unbalanced Data}},
url = {http://link.springer.com/10.1023/B:APIN.0000033632.42843.17},
volume = {21},
year = {2004}
}
@article{Naik2003,
abstract = {The first step in many techniques for processing intensity and saturation in color images keeping hue unaltered is the transformation of the image data from RGB space to other color spaces such as LHS, HSI, YIQ, HSV, etc. Transforming from one space to another and processing in these spaces usually generate a gamut problem, i.e., the values of the variables may not be in their respective intervals. We study enhancement techniques for color images theoretically in a generalized setup. A principle is suggested to make the transformations gamut-problem free. Using the same principle, a class of hue-preserving, contrast-enhancing transformations is proposed; they generalize existing grey scale contrast intensification techniques to color images. These transformations are also seen to bypass the above mentioned color coordinate transformations for image enhancement. The developed principle is used to generalize the histogram equalization scheme for grey scale images to color images.},
author = {Naik, Sarif K and Murthy, C A},
doi = {10.1109/TIP.2003.819231},
file = {:home/serrano/Documents/eBooks/Mendeley/IEEE transactions on image processing a publication of the IEEE Signal Processing Society/Naik, Murthy/Naik, Murthy - 2003 - Hue-preserving color image enhancement without gamut problem.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = jan,
number = {12},
pages = {1591--8},
pmid = {18244713},
title = {{Hue-preserving color image enhancement without gamut problem}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18244713},
volume = {12},
year = {2003}
}
@inproceedings{Nilsback2008,
address = {Bhubaneswar},
author = {Nilsback, Maria-Elena and Zisserman, Andrew},
booktitle = {2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
doi = {10.1109/ICVGIP.2008.47},
file = {:home/serrano/Documents/eBooks/Mendeley/2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing/Nilsback, Zisserman/Nilsback, Zisserman - 2008 - Automated Flower Classification over a Large Number of Classes.pdf:pdf},
month = dec,
pages = {722--729},
publisher = {IEEE},
title = {{Automated Flower Classification over a Large Number of Classes}},
year = {2008}
}
@article{Nissen2005,
author = {Nissen, Steffen},
file = {::},
journal = {Software 2.0},
pages = {14--19},
title = {{Neural networks made simple}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Neural+networks+made+simple\#1},
year = {2005}
}
@techreport{Nissen2003,
abstract = {This report describes the implementation of a fast artificial neural network library in ANSI C called fann. The library implements multilayer feedforward networks with support for both fully connected and sparse connected net- works. Fann offers support for execution in fixed point arithmetic to allow for fast execution on systems with no floating point processor. To overcome the problems of integer overflow, the library calculates a position of the decimal point after training and guarantees that integer overflow can not occur with this decimal point. The library is designed to be fast, versatile and easy to use. Several bench- marks have been executed to test the performance of the library. The results show that the fann library is significantly faster than other libraries on systems without a floating point processor, while the performance was comparable to other highly optimized libraries on systems with a floating point processor.},
author = {Nissen, Steffen},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Nissen/Nissen - 2003 - Implementation of a Fast Artificial Neural Network Library (FANN).pdf:pdf},
institution = {Department of Computer Science University of Copenhagen (DIKU)},
keywords = {ann,ansi c,artificial neural network,fixed,performance engineering,point arithmetic},
title = {{Implementation of a Fast Artificial Neural Network Library (FANN)}},
year = {2003}
}
@phdthesis{Nissen2007,
author = {Nissen, Steffen},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Nissen/Nissen - 2007 - Large Scale Reinforcement Learning using Q-SARSA($\lambda$) and Cascading Neural Networks.pdf:pdf},
school = {University of Copenhagen},
title = {{Large Scale Reinforcement Learning using Q-SARSA($\lambda$) and Cascading Neural Networks}},
year = {2007}
}
@article{Orlov2008,
author = {Orlov, Nikita and Shamir, Lior and Macura, Tomasz and Johnston, Josiah and Eckley, D. Mark and Goldberg, Ilya G.},
doi = {10.1016/j.patrec.2008.04.013},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition Letters/Orlov et al/Orlov et al. - 2008 - WND-CHARM Multi-purpose image classification using compound image transforms.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {image classification},
month = aug,
number = {11},
pages = {1684--1693},
title = {{WND-CHARM: Multi-purpose image classification using compound image transforms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865508001530},
volume = {29},
year = {2008}
}
@article{Ou2007,
author = {Ou, Guobin and Murphey, Yi Lu},
doi = {10.1016/j.patcog.2006.04.041},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition/Ou, Murphey/Ou, Murphey - 2007 - Multi-class pattern classification using neural networks.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {machine learning,multi-class classification,neural networks,pattern recognition},
month = jan,
number = {1},
pages = {4--18},
title = {{Multi-class pattern classification using neural networks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320306002081},
volume = {40},
year = {2007}
}
@article{Pal1993,
author = {Pal, Nikhil R and Pal, Sankar K.},
doi = {10.1016/0031-3203(93)90135-J},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition/Pal, Pal/Pal, Pal - 1993 - A review on image segmentation techniques.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = sep,
number = {9},
pages = {1277--1294},
title = {{A review on image segmentation techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/003132039390135J},
volume = {26},
year = {1993}
}
@article{Pedregosa2011,
author = {Pedregosa, Fabian and Weiss, Ron and Brucher, Matthieu},
file = {:home/serrano/Documents/eBooks/Mendeley/Journal of Machine Learning Research/Pedregosa, Weiss, Brucher/Pedregosa, Weiss, Brucher - 2011 - Scikit-learn Machine Learning in Python.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://jmlr.org/papers/v12/pedregosa11a.html},
volume = {12},
year = {2011}
}
@book{Pridgeon1999,
address = {Oxford},
author = {Pridgeon, Alec M. and Cribb, Phillip J. and Chase, Mark W. and Rasmussen, Finn N.},
isbn = {9780198505136},
pages = {230},
publisher = {Oxford University Press},
title = {{Genera Orchidacearum Volume 1: Apostasioideae and Cypripedioideae}},
year = {1999}
}
@article{Pulli2012,
author = {Pulli, Kari and Baksheev, Anatoly and Kornyakov, Kirill and Eruhimov, Victor},
doi = {10.1145/2184319.2184337},
file = {:home/serrano/Documents/eBooks/Mendeley/Communications of the ACM/Pulli et al/Pulli et al. - 2012 - Real-time computer vision with OpenCV.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = jun,
number = {6},
pages = {61},
title = {{Real-time computer vision with OpenCV}},
url = {http://dl.acm.org/citation.cfm?doid=2184319.2184337},
volume = {55},
year = {2012}
}
@article{Rother2004,
abstract = {The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.},
author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
file = {:home/serrano/Documents/eBooks/Mendeley/ACM Transactions on Graphics (SIGGRAPH)/Rother, Kolmogorov, Blake/Rother, Kolmogorov, Blake - 2004 - GrabCut — Interactive Foreground Extraction using Iterated Graph Cuts.pdf:pdf},
journal = {ACM Transactions on Graphics (SIGGRAPH)},
keywords = {alpha matting,at,degrees of interactive effort,editing,foreground extraction,free of colour bleeding,from the source background,graph cuts,image,in general,interactive image segmentation,pixels,range from editing individual},
title = {{GrabCut — Interactive Foreground Extraction using Iterated Graph Cuts}},
url = {http://research.microsoft.com/apps/pubs/default.aspx?id=67890},
year = {2004}
}
@article{Sanz2013,
author = {Sanz, Ernesto and {Von Cramon Taubadel}, Noreen and Roberts, David L.},
doi = {10.15517/lank.v0i0.11743},
file = {:home/serrano/Documents/eBooks/Mendeley/Lankesteriana/Sanz, Von Cramon Taubadel, Roberts/Sanz, Von Cramon Taubadel, Roberts - 2013 - Species differentiation of slipper orchids using color image analysis.pdf:pdf},
issn = {1409-3871},
journal = {Lankesteriana},
keywords = {ambos con gran importancia,colores para diferenciar especies,el uso de los,en este art\'{\i}culo investigamos,en la horticultura,en los g\'{e}neros paphiopedilum,existen l\'{\i}mites debido a,geometr\'{\i}a morfom\'{e}trica,han utilizado sistemas de,la capacidad de discriminaci\'{o}n,la necesidad de encontrar,los diferentes organismos,phragmipedium,puntos de georreferenciaci\'{o}n en,reconocimiento autom\'{a}tico basados en,sin embargo,var\'{\i}a entre los,y},
month = aug,
number = {3},
pages = {165 -- 173},
title = {{Species differentiation of slipper orchids using color image analysis}},
url = {http://revistas.ucr.ac.cr/index.php/lankesteriana/article/view/11743},
volume = {12},
year = {2013}
}
@article{Shamir2010,
abstract = {The increasing prevalence of automated image acquisition systems is enabling new types of microscopy experiments that generate large image datasets. However, there is a perceived lack of robust image analysis systems required to process these diverse datasets. Most automated image analysis systems are tailored for specific types of microscopy, contrast methods, probes, and even cell types. This imposes significant constraints on experimental design, limiting their application to the narrow set of imaging methods for which they were designed. One of the approaches to address these limitations is pattern recognition, which was originally developed for remote sensing, and is increasingly being applied to the biology domain. This approach relies on training a computer to recognize patterns in images rather than developing algorithms or tuning parameters for specific image processing tasks. The generality of this approach promises to enable data mining in extensive image repositories, and provide objective and quantitative imaging assays for routine use. Here, we provide a brief overview of the technologies behind pattern recognition and its use in computer vision for biological and biomedical imaging. We list available software tools that can be used by biologists and suggest practical experimental considerations to make the best use of pattern recognition techniques for imaging assays.},
author = {Shamir, Lior and Delaney, John D and Orlov, Nikita and Eckley, D Mark and Goldberg, Ilya G},
doi = {10.1371/journal.pcbi.1000974},
file = {:home/serrano/Documents/eBooks/Mendeley/PLoS computational biology/Shamir et al/Shamir et al. - 2010 - Pattern recognition software and techniques for biological image analysis.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,Image Processing, Computer-Assisted,Pattern Recognition, Automated,Software},
month = jan,
number = {11},
pages = {e1000974},
pmid = {21124870},
title = {{Pattern recognition software and techniques for biological image analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2991255\&tool=pmcentrez\&rendertype=abstract},
volume = {6},
year = {2010}
}
@article{Shamir2008,
abstract = {BACKGROUND: Biological imaging is an emerging field, covering a wide range of applications in biological and clinical research. However, while machinery for automated experimenting and data acquisition has been developing rapidly in the past years, automated image analysis often introduces a bottleneck in high content screening. METHODS: Wndchrm is an open source utility for biological image analysis. The software works by first extracting image content descriptors from the raw image, image transforms, and compound image transforms. Then, the most informative features are selected, and the feature vector of each image is used for classification and similarity measurement. RESULTS: Wndchrm has been tested using several publicly available biological datasets, and provided results which are favorably comparable to the performance of task-specific algorithms developed for these datasets. The simple user interface allows researchers who are not knowledgeable in computer vision methods and have no background in computer programming to apply image analysis to their data. CONCLUSION: We suggest that wndchrm can be effectively used for a wide range of biological image analysis tasks. Using wndchrm can allow scientists to perform automated biological image analysis while avoiding the costly challenge of implementing computer vision and pattern recognition algorithms.},
author = {Shamir, Lior and Orlov, Nikita and Eckley, D Mark and Macura, Tomasz and Johnston, Josiah and Goldberg, Ilya G},
doi = {10.1186/1751-0473-3-13},
file = {:home/serrano/Documents/eBooks/Mendeley/Source code for biology and medicine/Shamir et al/Shamir et al. - 2008 - Wndchrm - an open source utility for biological image analysis.pdf:pdf},
issn = {1751-0473},
journal = {Source code for biology and medicine},
month = jan,
pages = {13},
pmid = {18611266},
title = {{Wndchrm - an open source utility for biological image analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2478650\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2008}
}
@phdthesis{SimonXinmengLiao1993,
author = {{Simon Xinmeng Liao}},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Simon Xinmeng Liao/Simon Xinmeng Liao - 1993 - Image analysis by moments.pdf:pdf},
school = {University of Manitoba},
title = {{Image analysis by moments}},
year = {1993}
}
@article{Tahmasbi2011,
abstract = {In mammography diagnosis systems, high False Negative Rate (FNR) has always been a significant problem since a false negative answer may lead to a patient's death. This paper is directed towards the development of a novel Computer-aided Diagnosis (CADx) system for the diagnosis of breast masses. It aims at intensifying the performance of CADx algorithms as well as reducing the FNR by utilizing Zernike moments as descriptors of shape and margin characteristics. The input Regions of Interest (ROIs) are segmented manually and further subjected to a number of preprocessing stages. The outcomes of preprocessing stage are two processed images containing co-scaled translated masses. Besides, one of these images represents the shape characteristics of the mass, while the other describes the margin characteristics. Two groups of Zernike moments have been extracted from the preprocessed images and applied to the feature selection stage. Each group includes 32 moments with different orders and iterations. Considering the performance of the overall CADx system, the most effective moments have been chosen and applied to a Multi-layer Perceptron (MLP) classifier, employing both generic Back Propagation (BP) and Opposition-based Learning (OBL) algorithms. The Receiver Operational Characteristics (ROC) curve and the performance of resulting CADx systems are analyzed for each group of features. The designed systems yield Az=0.976, representing fair sensitivity, and Az=0.975 demonstrating fair specificity. The best achieved FNR and FPR are 0.0\% and 5.5\%, respectively.},
author = {Tahmasbi, Amir and Saki, Fatemeh and Shokouhi, Shahriar B},
doi = {10.1016/j.compbiomed.2011.06.009},
file = {:home/serrano/Documents/eBooks/Mendeley/Computers in biology and medicine/Tahmasbi, Saki, Shokouhi/Tahmasbi, Saki, Shokouhi - 2011 - Classification of benign and malignant masses based on Zernike moments.pdf:pdf},
issn = {1879-0534},
journal = {Computers in biology and medicine},
keywords = {Algorithms,Breast Neoplasms,Breast Neoplasms: classification,Breast Neoplasms: radiography,Breast Neoplasms: ultrasonography,Databases, Factual,Diagnosis, Computer-Assisted,Diagnosis, Computer-Assisted: methods,Female,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Mammography,Mammography: methods,Neural Networks (Computer),ROC Curve,Sensitivity and Specificity},
month = aug,
number = {8},
pages = {726--35},
pmid = {21722886},
publisher = {Elsevier},
title = {{Classification of benign and malignant masses based on Zernike moments.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21722886},
volume = {41},
year = {2011}
}
@article{Teh1988,
author = {Teh, C.-H. and Chin, R.T.},
doi = {10.1109/34.3913},
file = {:home/serrano/Documents/eBooks/Mendeley/IEEE Transactions on Pattern Analysis and Machine Intelligence/Teh, Chin/Teh, Chin - 1988 - On image analysis by the methods of moments.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = jul,
number = {4},
pages = {496--513},
title = {{On image analysis by the methods of moments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=3913},
volume = {10},
year = {1988}
}
@article{VanderNiet2010,
abstract = {Variation in floral shape is of major interest to evolutionary and pollination biologists, plant systematists and developmental geneticists. Quantifying this variation has been difficult due to the three-dimensional (3D) complexity of angiosperm flowers. By combining 3D geometric representations of flowers obtained by micro-computed tomography scanning with geometric morphometric methods, well established in zoology and anthropology, floral shape variation can be analyzed quantitatively, allowing for powerful interpretation and visualization of the resulting patterns of variation.},
author = {van der Niet, Timothe\"{u}s and Zollikofer, Christoph P E and de Le\'{o}n, Marcia S Ponce and Johnson, Steven D and Linder, H Peter},
doi = {10.1016/j.tplants.2010.05.005},
file = {:home/serrano/Documents/eBooks/Mendeley/Trends in plant science/van der Niet et al/van der Niet et al. - 2010 - Three-dimensional geometric morphometrics for studying floral shape variation.pdf:pdf},
issn = {1878-4372},
journal = {Trends in plant science},
keywords = {Angiosperms,Angiosperms: anatomy \& histology,Biological Evolution,Botany,Botany: methods,Flowers,Flowers: anatomy \& histology,Imaging,Three-Dimensional},
month = aug,
number = {8},
pages = {423--6},
pmid = {20541450},
title = {{Three-dimensional geometric morphometrics for studying floral shape variation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20541450},
volume = {15},
year = {2010}
}
@article{VanderWalt2011,
abstract = {In the Python world, NumPy arrays are the standard representation for numerical data. Here, we show how these arrays enable efficient implementation of numerical computations in a high-level language. Overall, three techniques are applied to improve performance: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts. We first present the NumPy array structure, then show how to use it for efficient computation, and finally how to share array data with other libraries.},
archivePrefix = {arXiv},
arxivId = {1102.1523},
author = {van der Walt, Stéfan and Colbert, S. Chris and Varoquaux, Gaël},
doi = {10.1109/MCSE.2011.37},
eprint = {1102.1523},
file = {:home/serrano/Documents/eBooks/Mendeley/Computing in Science \& Engineering/van der Walt, Colbert, Varoquaux/van der Walt, Colbert, Varoquaux - 2011 - The NumPy Array A Structure for Efficient Numerical Computation.pdf:pdf},
issn = {1521-9615},
journal = {Computing in Science \& Engineering},
month = mar,
number = {2},
pages = {22--30},
title = {{The NumPy Array: A Structure for Efficient Numerical Computation}},
url = {http://arxiv.org/abs/1102.1523 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5725236},
volume = {13},
year = {2011}
}
@article{Vinyals,
archivePrefix = {arXiv},
arxivId = {1411.4555v1},
author = {Vinyals, Oriol and Toshev, Alexander},
eprint = {1411.4555v1},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Vinyals, Toshev/Vinyals, Toshev - Unknown - Show and Tell A Neural Image Caption Generator.pdf:pdf},
title = {{Show and Tell: A Neural Image Caption Generator}},
url = {http://arxiv.org/abs/1411.4555}
}
@article{Wang2007,
author = {Wang, Shubing},
file = {:home/serrano/Documents/eBooks/Mendeley/Unknown/Wang/Wang - 2007 - Applications of Fourier Transform to Imaging Analysis.pdf:pdf},
title = {{Applications of Fourier Transform to Imaging Analysis}},
year = {2007}
}
@article{Weeks1999,
author = {Weeks, P. J. D. and O’Neill, M. A. and Gaston, K. J. and Gauld, I D},
doi = {10.1046/j.1439-0418.1999.00307.x},
file = {:home/serrano/Documents/eBooks/Mendeley/Journal of Applied Entomology/Weeks et al/Weeks et al. - 1999 - Automating insect identification exploring the limitations of a prototype system.pdf:pdf},
issn = {09312048},
journal = {Journal of Applied Entomology},
month = jan,
number = {1},
pages = {1--8},
title = {{Automating insect identification: exploring the limitations of a prototype system}},
url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1439-0418.1999.00307.x/full http://doi.wiley.com/10.1046/j.1439-0418.1999.00307.x},
volume = {123},
year = {1999}
}
@article{Weeks1997,
author = {Weeks, Paul J. D. and Gaston, Kevin J.},
doi = {10.1023/a:1018348204573},
file = {:home/serrano/Documents/eBooks/Mendeley/Biodiversity and Conservation/Weeks, Gaston/Weeks, Gaston - 1997 - Image analysis, neural networks, and the taxonomic impediment to biodiversity studies.pdf:pdf},
journal = {Biodiversity and Conservation},
keywords = {biodiversity,identification,image analysis,neural networks,taxonomy},
number = {2},
pages = {263--274},
title = {{Image analysis, neural networks, and the taxonomic impediment to biodiversity studies}},
url = {http://dx.doi.org/10.1023/A:1018348204573},
volume = {6},
year = {1997}
}
@article{York2008,
author = {York, Amber and Gallager, Scott and Taylor, Richard and Vine, Norman and Lerner, Steve},
doi = {10.1109/OCEANS.2008.5152001},
file = {:home/serrano/Documents/eBooks/Mendeley/Oceans 2008/York et al/York et al. - 2008 - Using a towed optical habitat mapping system to monitor the invasive tunicate species Didemnum sp. along the northe.pdf:pdf},
isbn = {978-1-4244-2619-5},
journal = {Oceans 2008},
pages = {1--9},
publisher = {Ieee},
title = {{Using a towed optical habitat mapping system to monitor the invasive tunicate species Didemnum sp. along the northeast continental shelf}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152001},
year = {2008}
}
@article{Zhao2004,
author = {Zhao, Zhong-Qiu and Huang, De-Shuang and Sun, Bing-Yu},
doi = {10.1016/j.patrec.2004.05.008},
file = {:home/serrano/Documents/eBooks/Mendeley/Pattern Recognition Letters/Zhao, Huang, Sun/Zhao, Huang, Sun - 2004 - Human face recognition based on multi-features using neural networks committee.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {classification,face recognition,feature domain,kernel methods,neural networks committee},
month = sep,
number = {12},
pages = {1351--1358},
title = {{Human face recognition based on multi-features using neural networks committee}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504001047},
volume = {25},
year = {2004}
}
